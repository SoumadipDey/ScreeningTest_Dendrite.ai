{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVK4QwBqla7atGJWdzauZM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoumadipDey/ScreeningTest_Dendrite.ai/blob/main/Dendrite_ai_Screening_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fetching the data and parameters**"
      ],
      "metadata": {
        "id": "Qb_Fflqd1EJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/SoumadipDey/ScreeningTest_Dendrite.ai/raw/a41fb019783d8820a1f5ca081013c4df2d98874f/algoparams_from_ui.json.rtf --quiet\n",
        "!wget https://github.com/SoumadipDey/ScreeningTest_Dendrite.ai/raw/a41fb019783d8820a1f5ca081013c4df2d98874f/iris.csv --quiet"
      ],
      "metadata": {
        "id": "5Yl4hbMN0V7e"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing packages**"
      ],
      "metadata": {
        "id": "HF-F0zAworpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install striprtf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77xJTS8houa0",
        "outputId": "a65ab268-9295-404d-ddc2-a84741675ff6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: striprtf in /usr/local/lib/python3.10/dist-packages (0.0.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Priliminary Actions**"
      ],
      "metadata": {
        "id": "Q1O_g-BWN0Ed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the library functions**"
      ],
      "metadata": {
        "id": "oOAh1vXZN5QR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XlIZA5pENosD"
      },
      "outputs": [],
      "source": [
        "import json as json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from striprtf.striprtf import rtf_to_text\n",
        "\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor,ExtraTreesClassifier\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet, SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Declaring a few globals**"
      ],
      "metadata": {
        "id": "mysQU9ijo4xQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IRIS_PATH = \"/content/iris.csv\"\n",
        "PARAMS_PATH = \"/content/algoparams_from_ui.json.rtf\""
      ],
      "metadata": {
        "id": "uk3XuGNHo8ry"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting `algoparams_from_ui.rtf` to Dictionary**"
      ],
      "metadata": {
        "id": "ukinlSNYoSCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convertRtfToDict(path: str) -> dict:\n",
        "  param_file = open(path,'r')\n",
        "  param_file_content = param_file.read()\n",
        "  param_file_content = rtf_to_text(param_file_content)\n",
        "  param_file.close()\n",
        "  return json.loads(param_file_content)\n",
        "allParams = convertRtfToDict(PARAMS_PATH)"
      ],
      "metadata": {
        "id": "me16FL9XoQH4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting important parameters from the `allParams` Dictionary**"
      ],
      "metadata": {
        "id": "9iX9eP_Lz9_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_handling_params = allParams['design_state_data']['feature_handling']\n",
        "algorithm_params = allParams['design_state_data']['algorithms']\n",
        "feature_reduction_params = allParams['design_state_data']['feature_reduction']\n",
        "hyperparameters_params = allParams['design_state_data']['hyperparameters']\n",
        "target_params = allParams['design_state_data']['target']"
      ],
      "metadata": {
        "id": "xPJuMLaAzfzR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predType = target_params['prediction_type']\n",
        "targetFeature = target_params['target']\n",
        "featuresUsed = [feature for feature in feature_handling_params if feature_handling_params[feature]['is_selected']]\n",
        "algorithmsUsed = [algo for algo in algorithm_params if algorithm_params[algo]['is_selected']]"
      ],
      "metadata": {
        "id": "CncjD57ksfTG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Features:\",featuresUsed)\n",
        "print(\"Target:\",targetFeature)\n",
        "print(\"Prediction type:\",predType)\n",
        "print(\"Algorithms used:\",algorithmsUsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7I8YhCMxLHd",
        "outputId": "39655b9e-e7f8-4575-bac3-c2ab922848cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
            "Target: petal_width\n",
            "Prediction type: Regression\n",
            "Algorithms used: ['RandomForestRegressor']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading and splitting the dataset as required**"
      ],
      "metadata": {
        "id": "vpgokvw13vPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadAndSplitDataset(path: str, target: str, features: list, val_split: float = 0.25, random_state : int = 42):\n",
        "  df = pd.read_csv(path)\n",
        "  y = df[[target]].values.reshape(-1,1)\n",
        "\n",
        "  if(target in features):\n",
        "    features.remove(target)\n",
        "\n",
        "  X_df = df.drop([target], axis = 1)[features]\n",
        "  featurePositions = {val:index for index,val in enumerate(X_df.columns)}\n",
        "\n",
        "  X = X_df.values\n",
        "  return train_test_split(X, y, test_size = val_split, random_state = random_state), featurePositions\n",
        "\n",
        "(X_train, X_test, y_train, y_test), featurePositions = loadAndSplitDataset(IRIS_PATH,targetFeature,featuresUsed)"
      ],
      "metadata": {
        "id": "evgwP2z_3yEC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating an Estimator Buffet object which will make it easier for us to create estimator object**"
      ],
      "metadata": {
        "id": "dACkTA10nbha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimatorBuffet = {\"Classification\":{\"RandomForestClassifier\":RandomForestClassifier(),\n",
        "                                \"GBTClassifier\":GradientBoostingClassifier(),\n",
        "                                \"LogisticRegression\":LogisticRegression(),\n",
        "                                \"xg_boost\":xgb.XGBClassifier(),\n",
        "                                \"DecisionTreeClassifier\":DecisionTreeClassifier(),\n",
        "                                \"SVM\":SVC(),\n",
        "                                \"SGD\":SGDClassifier(),\n",
        "                                \"KNN\":KNeighborsClassifier(),\n",
        "                                \"extra_random_trees\":ExtraTreesClassifier(),\n",
        "                                \"neural_network\":MLPClassifier()},\n",
        "                  \"Regression\":{\"RandomForestRegressor\":RandomForestRegressor(),\n",
        "                               \"GBTRegressor\":GradientBoostingRegressor(),\n",
        "                               \"LinearRegression\":LinearRegression(),\n",
        "                               \"RidgeRegression\":Ridge(),\n",
        "                               \"LassoRegression\":Lasso(),\n",
        "                               \"ElasticNetRegression\":ElasticNet(),\n",
        "                               \"DecisionTreeRegressor\":DecisionTreeRegressor()}}\n"
      ],
      "metadata": {
        "id": "9cUasw_GYFnG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Column Transformer for missing value imputation and Feature Hash encoding the Categorical feature**"
      ],
      "metadata": {
        "id": "7eS56vYj-gTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createImputersAndEncoders(features :list, target :str):\n",
        "  if(target in features):\n",
        "    features.remove(target)\n",
        "  transformerList = []\n",
        "  for feature in features:\n",
        "    feature_handling = feature_handling_params[feature]\n",
        "    if(feature_handling['feature_variable_type'] == \"numerical\"):\n",
        "      if(feature_handling['feature_details']['missing_values'] == \"Impute\"):\n",
        "        if(feature_handling['feature_details']['impute_with'] == \"Average of values\"):\n",
        "          imputer = SimpleImputer(strategy = 'mean')\n",
        "          transformerList.append((f'{feature}_imputer',imputer,[featurePositions[feature]]))\n",
        "        elif(feature_handling['feature_details']['impute_with'] == \"custom\"):\n",
        "          imputer = SimpleImputer(strategy = 'constant', fill_value = feature_handling['feature_details']['impute_value'])\n",
        "          transformerList.append((f'{feature}_imputer',imputer,[featurePositions[feature]]))\n",
        "    else:\n",
        "      if(feature_handling['feature_details']['text_handling'] == \"Tokenize and hash\"):\n",
        "        encoder = FeatureHasher(n_features = 2, input_type=\"string\")\n",
        "        transformerList.append((f'{feature}_encoder',encoder,[featurePositions[feature]]))\n",
        "\n",
        "  return transformerList"
      ],
      "metadata": {
        "id": "mvG2Yz_XK28E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputeEncodeTransformer = ColumnTransformer(createImputersAndEncoders(featuresUsed,targetFeature), remainder='passthrough')"
      ],
      "metadata": {
        "id": "1wh5xnvz8IOq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Column Transformer for Feature Reduction**"
      ],
      "metadata": {
        "id": "f9Xx4XRCv_Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aCEEOZ4lv_tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating the pipeline**"
      ],
      "metadata": {
        "id": "8V1V6bjZ8dtc"
      }
    }
  ]
}